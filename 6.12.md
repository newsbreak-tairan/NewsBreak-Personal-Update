# 12th June - DTR Personal Update
## 1 - Why are pipelines and other settings written here instead of the configuration file?

In the Scrapy framework, `custom_settings` is used to override global settings specifically for a particular Spider. This is done for several reasons:

1. **Flexibility**: Different Spiders may require different configurations. For example, one Spider might need a different Item Pipeline or a different concurrency level compared to another. Using `custom_settings` allows you to easily customize settings for each Spider without modifying the global `settings.py` file.

2. **Modularity**: Keeping settings with the Spider's logic makes the code easier to manage and understand. Developers can see all relevant configurations for a Spider in one place, rather than having to look through multiple files.

3. **Avoiding Global Impact**: Settings in the global `settings.py` file affect all Spiders. If you need specific configurations for just one or a few Spiders, using `custom_settings` is a better approach.

### Can the Scrapy framework manage data passing, etc., through these settings?

Yes, the Scrapy framework fully supports managing various configurations, including data passing, concurrency control, download delays, pipelines, etc., through the `custom_settings` in the Spider class. These settings will override the corresponding global settings for that specific Spider.

### Common Configuration Options in `custom_settings`

Some common options you might set in `custom_settings` include:

- **ITEM_PIPELINES**: Defines the Item Pipeline and their order.
- **CONCURRENT_ITEMS**: The maximum number of items to process concurrently.
- **CONCURRENT_REQUESTS**: The maximum number of concurrent requests the Scrapy downloader should be allowed.
- **CONCURRENT_REQUESTS_PER_DOMAIN**: The maximum number of concurrent requests allowed per domain.
- **DOWNLOAD_DELAY**: The delay between requests to the same website.
- **DOWNLOAD_TIMEOUT**: The download timeout period.

### Example

`custom_settings` overrides several key configurations:

```python
custom_settings = {
    'ITEM_PIPELINES': {
        'scheduled_ingest.utils.updater_pipline.UpdaterPipline': 40,
        'scheduled_ingest.utils.pipelines.DownstreamWriter': 80,
    },
    'CONCURRENT_ITEMS': 1024 * 10,
    'CONCURRENT_REQUESTS': 1024,
    'CONCURRENT_REQUESTS_PER_DOMAIN': 1024,
    'DOWNLOAD_TIMEOUT': 180
}
```

These settings will be effective for this particular Spider, without affecting other Spiders or the global settings. For example:

- **ITEM_PIPELINES**: Defines two Item Pipelines with their priority levels.
- **CONCURRENT_ITEMS**, **CONCURRENT_REQUESTS**, **CONCURRENT_REQUESTS_PER_DOMAIN**: Sets a high level of concurrency.
- **DOWNLOAD_TIMEOUT**: Sets a longer download timeout.

In summary, `custom_settings` provides a flexible way to customize settings for different Spiders, making project management more efficient and clearer.
